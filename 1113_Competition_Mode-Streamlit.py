# -*- coding: utf-8 -*-
"""
1111 New CVS-DE Testing-Streamlit.py
Streamlit app for Classical Variable Sampling (CVS-DE)
- Bilingual UI (ä¸­æ–‡/English)
- Upload Excel with sheet 'CVS-DE'
- Modes: Symmetric / Asymmetric / Both
- CPI uses sample SD (ddof=1), symmetric halfwidth = CPI (Excel-consistent)
- Export fixed path: H:\VS Code-Auditing\output-CVS-DE.xlsx + browser download
- Teaching Mode (bottom, collapsible): Variable Glossary + numbered formulas (Symmetric only)

Run:
    streamlit run "1111 New CVS-DE Testing-Streamlit.py"
"""

import io
import math
import os
from typing import Any, Dict, Optional, Tuple
import numpy as np
import pandas as pd
import streamlit as st
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows

import datetime

# ===== Fixed output path (for local Excel export) =====
FIXED_OUT_PATH = r"H:\VS Code-Auditing\output-CVS-DE.xlsx"

# ===== Confidence level to (ZA, ZR) map (if you ever want auto-mode) =====
CONF_LEVEL_MAP: Dict[str, Tuple[float, float]] = {
    # key: "overall CL" â†’ (ZA, ZR)  (not currently auto-used, but kept for extension)
    "99": (2.33, 2.58),
    "95": (1.65, 1.96),
    "90": (1.28, 1.64),
    "80": (0.84, 1.28),
}

# ===== Small formatting helpers =====
def fmt2(x: float) -> str:
    try:
        return f"{x:,.2f}"
    except Exception:
        return str(x)

def fmt4(x: float) -> str:
    try:
        return f"{x:,.4f}"
    except Exception:
        return str(x)

def fmt_int(x: float) -> str:
    try:
        return f"{int(round(x)):,}"
    except Exception:
        return str(x)

def safe_number(x: Any) -> Optional[float]:
    try:
        return float(x)
    except Exception:
        return None

# ===== Load sample block from uploaded Excel (sheet CVS-DE) =====
def load_sample_block_from_uploaded(file_buffer):
    raw = pd.read_excel(file_buffer, sheet_name="CVS-DE", header=None)

    def row_has_header(sr: pd.Series) -> bool:
        s = sr.astype(str).str.lower()
        return s.str.contains("account no", na=False).any() or s.str.contains("account number", na=False).any()

    header_idx_list = raw.index[raw.apply(row_has_header, axis=1)].tolist()
    if not header_idx_list:
        raise RuntimeError("æ‰¾ä¸åˆ°è¡¨é ­åˆ—ï¼ˆéœ€å« 'Account NO.' æˆ– 'Account Number'ï¼‰")
    header_idx = header_idx_list[0]

    data = raw.iloc[header_idx + 1:, 0:4].copy()
    data.columns = [
        "Account Number",
        "Recorded Accounts",
        "Audited Accounts",
        "Factual Misstatement (ej)",
    ]

    # Trim spaces
    data["Account Number"] = data["Account Number"].astype(str).str.strip()

    # Stop at first row containing 'Total' in Account Number
    stop_idx = data.index[data["Account Number"].astype(str).str.contains("Total", case=False, na=False)]
    if len(stop_idx) > 0:
        data = data.loc[: stop_idx[0] - 1]

    # Cast numeric for main numeric columns
    for c in ["Recorded Accounts", "Audited Accounts", "Factual Misstatement (ej)"]:
        data[c] = pd.to_numeric(data[c], errors="coerce")

    # --- Stability patch: remove non-numeric Account Number rows (e.g., "Total", text, blanks) ---
    # This prevents Arrow / Streamlit from failing when converting to numeric types internally.
    data["AN_numeric"] = pd.to_numeric(data["Account Number"], errors="coerce")
    data = data[data["AN_numeric"].notna()].copy()
    data.drop(columns=["AN_numeric"], inplace=True)

    e_series = data["Factual Misstatement (ej)"].dropna()
    m = int(e_series.shape[0])
    sum_e = float(e_series.sum())
    visible_rows = int(data.shape[0])
    return data, e_series, m, sum_e, visible_rows

# ===== Core compute (Excel-consistent CPI & intervals) =====
def compute_all(
    SD_star: float, ZA: float, ZR: float, N: int, TM: float, E_star: float,
    e_series: pd.Series, m: int, sum_e: float, n_override: Optional[int]
) -> Dict[str, Any]:

    if TM <= E_star:
        raise ValueError("TM must be greater than E* to compute sample size (avoid division by zero).")

    # Auto sample size by formula
    n_auto_exact = ((SD_star * (ZA + ZR) * N) / (TM - E_star)) ** 2
    n_auto_int = int(math.ceil(n_auto_exact))

    if n_auto_int < 1:
        raise ValueError("Computed sample size n_auto is < 1, please check SD*, TM, E* settings.")

    # Use override if reasonable
    n = int(n_override) if (isinstance(n_override, int) and n_override >= 1) else n_auto_int
    if m > n:
        raise ValueError(f"Count of nonzero errors m={m} cannot exceed chosen sample size n={n}.")

    # Point estimate: eÌ„ = Î£e / n (fill zero for non-error draws)
    e_bar = sum_e / n
    e_full = np.concatenate([e_series.values, np.zeros(max(0, n - m))])
    SD_sample = float(np.std(e_full, ddof=1)) if n > 1 else 0.0  # Excel STDEV.S

    # SE(mean) using SD* with FPC
    SE_mean = SD_star / math.sqrt(n) * math.sqrt((N - n) / N)

    # Total misstatement
    T_hat = N * e_bar

    # CPIï¼ˆç”¨æ¨£æœ¬ SDï¼ŒExcel æ–¹æ³•ï¼‰
    CPI_amt = N * ZA * SD_sample / math.sqrt(n) * math.sqrt((N - n) / N)

    # Symmetric interval using CPI as half-width
    L_sym = T_hat - CPI_amt
    U_sym = T_hat + CPI_amt
    half_sym = CPI_amt

    # Asymmetric interval (lower = ZR, upper = ZA)
    L_asym = T_hat - N * ZR * SE_mean
    U_asym = T_hat + N * ZA * SE_mean
    half_L = T_hat - L_asym
    half_R = U_asym - T_hat

    # Decisions: compare upper bound vs TM
    dec_sym = "Accept" if U_sym <= TM else "Reject"
    dec_asym = "Accept" if U_asym <= TM else "Reject"

    return {
        "n_auto_exact": n_auto_exact,
        "n_auto_int": n_auto_int,
        "n_used": n,
        "inputs": {"SD_star": SD_star, "ZA": ZA, "ZR": ZR, "N": N, "TM": TM, "E_star": E_star, "m": m, "sum_e": sum_e},
        "e_bar": e_bar,
        "SD_sample": SD_sample,
        "SE_mean": SE_mean,
        "T_hat": T_hat,
        "CPI_amt": CPI_amt,
        "sym": {"Z_sym": None, "L": L_sym, "U": U_sym, "half": half_sym, "decision": dec_sym},
        "asym": {"ZA": ZA, "ZR": ZR, "L": L_asym, "U": U_asym, "half_L": half_L, "half_R": half_R, "decision": dec_asym},
    }

# ===== Results table (bilingual) =====
def build_results_table(res: Dict[str, Any]) -> pd.DataFrame:
    i = res["inputs"]
    sym = res["sym"]
    asym = res["asym"]

    rows = []

    # Block 1: Inputs + sample size
    rows.append(["n_auto", "Estimated sample size (auto)", "ä¼°è¨ˆæ¨£æœ¬é‡ï¼ˆå…¬å¼ï¼‰", fmt_int(res["n_auto_int"])])
    rows.append(["n_used", "Sample size actually used", "æ¡ç”¨æ¨£æœ¬é‡", fmt_int(res["n_used"])])
    rows.append(["N", "Population size", "æ¯é«”å¤§å°", fmt_int(i["N"])])
    rows.append(["SDâ˜…", "Estimated population SD (SDâ˜…)", "ä¼°è¨ˆæ¯é«”æ¨™æº–å·® SDâ˜…", fmt4(i["SD_star"])])
    rows.append(["ZA", "ARIA Z-factor", "èª¤å—éšª Z å€¼ ZA", fmt4(i["ZA"])])
    rows.append(["ZR", "ARIR Z-factor", "èª¤æ‹’éšª Z å€¼ ZR", fmt4(i["ZR"])])
    rows.append(["TM", "Tolerable misstatement (TM)", "å¯å®¹å¿éŒ¯èª¤ TM", fmt2(i["TM"])])
    rows.append(["Eâ˜…", "Expected misstatement (Eâ˜…)", "é æœŸéŒ¯èª¤ Eâ˜…", fmt2(i["E_star"])])

    # Block 2: Point estimate and SD
    rows.append(["eÌ„", "Sample mean error", "æ¨£æœ¬å¹³å‡èª¤å·® eÌ„", fmt4(res["e_bar"])])
    rows.append(["SD", "Sample SD (STDEV.S)", "æ¨£æœ¬æ¨™æº–å·® SD", fmt4(res["SD_sample"])])
    rows.append(["SE(mean)", "Std. error of mean (with FPC)", "å¹³å‡æ•¸æ¨™æº–èª¤ï¼ˆå«æœ‰é™æ¯é«”ä¿®æ­£ï¼‰", fmt4(res["SE_mean"])])
    rows.append(["TÌ‚", "Estimated total misstatement", "ç¸½èª¤å·®é»ä¼°è¨ˆ TÌ‚ = NÂ·eÌ„", fmt2(res["T_hat"])])
    rows.append(["CPI", "Confidence precision interval (halfwidth)", "ç²¾ç¢ºåº¦å€é–“ï¼ˆåŠå¯¬ CPIï¼‰", fmt2(res["CPI_amt"])])

    # Block 3: Symmetric interval
    rows.append(["Sym_L", "Symmetric lower bound", "å°ç¨±ä¿¡è³´å€é–“ä¸‹é™", fmt2(sym["L"])])
    rows.append(["Sym_U", "Symmetric upper bound", "å°ç¨±ä¿¡è³´å€é–“ä¸Šé™", fmt2(sym["U"])])
    rows.append(["Sym_half", "Symmetric halfwidth (CPI)", "å°ç¨±åŠå¯¬", fmt2(sym["half"])])
    rows.append(["Sym_decision", "Decision (Sym)", "æ±ºç­–ï¼ˆå°ç¨±ï¼‰", sym["decision"]])

    # Block 4: Asymmetric interval
    rows.append(["Asym_L", "Asymmetric lower bound", "éå°ç¨±ä¿¡è³´å€é–“ä¸‹é™", fmt2(asym["L"])])
    rows.append(["Asym_U", "Asymmetric upper bound", "éå°ç¨±ä¿¡è³´å€é–“ä¸Šé™", fmt2(asym["U"])])
    rows.append(["Asym_half_L", "Asymmetric left halfwidth", "å·¦å´åŠå¯¬", fmt2(asym["half_L"])])
    rows.append(["Asym_half_R", "Asymmetric right halfwidth", "å³å´åŠå¯¬", fmt2(asym["half_R"])])
    rows.append(["Asym_decision", "Decision (Asym)", "æ±ºç­–ï¼ˆéå°ç¨±ï¼‰", asym["decision"]])

    df = pd.DataFrame(rows, columns=["Key", "Item (EN)", "é …ç›®ï¼ˆä¸­æ–‡ï¼‰", "Value"])
    return df

# ===== Export to Excel (fixed path + download) =====
def export_to_excel(res_df: pd.DataFrame, work_df: pd.DataFrame) -> bytes:
    wb = Workbook()
    ws1 = wb.active
    ws1.title = "results"
    for r in dataframe_to_rows(res_df, index=False, header=True):
        ws1.append(r)

    ws2 = wb.create_sheet("workpapers")
    for r in dataframe_to_rows(work_df, index=False, header=True):
        ws2.append(r)

    # Apply accounting-like format to numeric-ish cells
    def set_thousand(ws):
        for row in ws.iter_rows(min_row=2):
            for cell in row:
                try:
                    float(cell.value)
                    cell.number_format = '#,##0.00'
                except Exception:
                    pass

    set_thousand(ws1)
    set_thousand(ws2)

    # Save to bytes buffer
    bio = io.BytesIO()
    wb.save(bio)
    bio.seek(0)

    # Also save to fixed local path (for your H:\ usage)
    try:
        os.makedirs(os.path.dirname(FIXED_OUT_PATH), exist_ok=True)
        wb.save(FIXED_OUT_PATH)
    except Exception as e:
        # Silent fail is okay for competition; you still get download
        print(f"[WARN] Failed to save fixed path Excel: {e}")

    return bio.getvalue()

# ===== Streamlit App =====
def main():
    st.set_page_config(page_title="Classical Variable Sampling (CVS-DE)", layout="wide")

    st.title("ğŸ“Š Classical Variable Sampling (CVS-DE)")
    st.markdown("### å¯©è¨ˆæŠ½æ¨£äº’å‹•å¹³å° Â· Classical Variable Sampling for Auditing")

    # Top info / timestamp
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.caption(f"Run time / åŸ·è¡Œæ™‚é–“ï¼š{now}")

    st.markdown(
        """
**èªªæ˜ / Description**

æœ¬ç³»çµ±ç¤ºç¯„ã€Œå‚³çµ±è®Šé‡æŠ½æ¨£ (Classical Variable Sampling)ã€åœ¨å¯©è¨ˆæŠ½æ¨£ä¸­çš„æ‡‰ç”¨ï¼Œ  
æä¾›æ¨£æœ¬é‡ä¼°è¨ˆã€é»ä¼°è¨ˆã€ç²¾ç¢ºåº¦å€é–“ (CPI)ã€å°ç¨±èˆ‡éå°ç¨±ä¿¡è³´å€é–“ï¼Œä»¥åŠæ±ºç­–åˆ¤æ–·ã€‚

This app demonstrates Classical Variable Sampling for audit sampling,
including sample size estimation, point estimate, CPI, symmetric/asymmetric confidence intervals, and decisions.
"""
    )

    st.sidebar.header("Step 1. ä¸Šå‚³æŸ¥æ ¸æ¨£æœ¬ Excel / Upload Excel")
    uploaded_file = st.sidebar.file_uploader("è«‹ä¸Šå‚³å«ã€CVS-DEã€å·¥ä½œè¡¨ä¹‹ Excel æª”æ¡ˆ", type=["xlsx"])

    st.sidebar.header("Step 2. è¼¸å…¥åƒæ•¸ / Input Parameters")

    colZA, colZR = st.sidebar.columns(2)
    ZA = colZA.number_input("ZA (èª¤å—éšªå› å­)", value=1.28, step=0.01, format="%.2f")
    ZR = colZR.number_input("ZR (èª¤æ‹’éšªå› å­)", value=1.15, step=0.01, format="%.2f")

    colN, colTM = st.sidebar.columns(2)
    N = int(colN.number_input("æ¯é«”å¤§å° N", value=4000, step=1))
    TM = colTM.number_input("å¯å®¹å¿éŒ¯èª¤ TM", value=21000.0, step=100.0)

    colE, colSD = st.sidebar.columns(2)
    E_star = colE.number_input("é æœŸéŒ¯èª¤ Eâ˜…", value=1500.0, step=100.0)
    SD_star = colSD.number_input("ä¼°è¨ˆæ¯é«”æ¨™æº–å·® SDâ˜…", value=20.0, step=0.1)

    st.sidebar.markdown("---")
    st.sidebar.write("**æ¨£æœ¬é‡æ§ç®¡ / Sample size control**")
    n_override = st.sidebar.number_input("ç¢ºèªæ¨£æœ¬é‡ nï¼ˆç•™ 0 ä»£è¡¨æ¡ç”¨å…¬å¼é è¨­ï¼‰", min_value=0, step=1, value=100)

    st.sidebar.markdown("---")
    mode = st.sidebar.radio(
        "ä¿¡è³´å€é–“æ¨¡å¼ / Interval mode",
        options=["Symmetric only", "Asymmetric only", "Both (ä¸¦åˆ—æ¯”è¼ƒ)"],
        index=2,
    )

    st.sidebar.markdown("---")
    teaching_mode = st.sidebar.checkbox("å•Ÿç”¨æ•™å­¸æ¨¡å¼ / Enable Teaching Mode", value=True)

    st.markdown("## ğŸ” åˆ†æçµæœ / Analysis Results")

    if uploaded_file is None:
        st.info("è«‹å¾å·¦å´ä¸Šå‚³å« CVS-DE å·¥ä½œè¡¨çš„ Excel æª”ã€‚ / Please upload an Excel file with sheet 'CVS-DE'.")
        return

    try:
        work_df, e_series, m, sum_e, visible_rows = load_sample_block_from_uploaded(uploaded_file)
    except Exception as e:
        st.error(f"è®€å–æ¨£æœ¬è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ / Error while reading sample block: {e}")
        return

    # Compute
    n_override_int = int(n_override) if n_override > 0 else None

    try:
        res = compute_all(SD_star, ZA, ZR, N, TM, E_star, e_series, m, sum_e, n_override_int)
    except Exception as e:
        st.error(f"è¨ˆç®—éç¨‹ç™¼ç”ŸéŒ¯èª¤ / Error in computation: {e}")
        return

    # Results table and workpapers
    results_df = build_results_table(res)
    left, right = st.columns(2)

    with left:
        st.markdown("### ğŸ“‘ çµæœæ‘˜è¦ / Summary table")
        st.dataframe(results_df.astype(str), width="stretch")

    with right:
        st.markdown("### ğŸ“‚ æŸ¥æ ¸æ¨£æœ¬ / Audit sample (workpapers)")
        st.caption(f"å¯è¦‹åˆ—æ•¸ (visible rows) = {visible_rows}, éé›¶èª¤å·®ç­†æ•¸ m = {m}")
        st.dataframe(work_df.astype(str), width="stretch")

    # Interval display block (according to mode)
    sym = res["sym"]
    asym = res["asym"]

    if mode in ["Symmetric only", "Both (ä¸¦åˆ—æ¯”è¼ƒ)"]:
        st.markdown("#### ğŸ¯ å°ç¨±ä¿¡è³´å€é–“ / Symmetric interval")
        st.write(f"ä¸‹é™ L = {fmt2(sym['L'])}, ä¸Šé™ U = {fmt2(sym['U'])}")
        st.write(f"åŠå¯¬ (CPI) = {fmt2(sym['half'])}")
        st.write(f"æ±ºç­– / Decision: **{sym['decision']}**")

    if mode in ["Asymmetric only", "Both (ä¸¦åˆ—æ¯”è¼ƒ)"]:
        st.markdown("#### âš–ï¸ éå°ç¨±ä¿¡è³´å€é–“ / Asymmetric interval")
        st.write(f"ä¸‹é™ L = {fmt2(asym['L'])}, ä¸Šé™ U = {fmt2(asym['U'])}")
        st.write(f"å·¦å´åŠå¯¬ = {fmt2(asym['half_L'])}, å³å´åŠå¯¬ = {fmt2(asym['half_R'])}")
        st.write(f"æ±ºç­– / Decision: **{asym['decision']}**")

    # Export section
    st.markdown("---")
    st.markdown("### ğŸ’¾ åŒ¯å‡ºçµæœ / Export to Excel")

    excel_bytes = export_to_excel(results_df, work_df)
    st.download_button(
        label="â¬‡ ä¸‹è¼‰çµæœ Excel / Download results Excel",
        data=excel_bytes,
        file_name="output-CVS-DE.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    st.caption(f"æœ¬æ©Ÿå¦å­˜è·¯å¾‘ï¼ˆè‹¥æˆåŠŸï¼‰ï¼š{FIXED_OUT_PATH}")

    # Teaching mode
    if teaching_mode:
        st.markdown("## ğŸ“˜ æ•™å­¸æ¨¡å¼ / Teaching Mode")

        tab1, tab2, tab3 = st.tabs([
            "ğŸ‘€ å¿«é€Ÿç†è§£ (For students)",
            "ğŸ“ é€æ­¥å…¬å¼ (In class)",
            "ğŸ“š å®Œæ•´å®šç¾© (Reference)"
        ])

        # ---------- Tab 1: å¿«é€Ÿç†è§£ ----------
        with tab1:
            st.markdown("""
    **ä¸€å¥è©±ç†è§£ CVS-DEï¼š**

    > æˆ‘å€‘ç”¨ã€Œæ¨£æœ¬èª¤å·®ã€ä¾†æ¨ä¼°ã€Œæ¯é«”ç¸½èª¤å·®ã€ï¼Œ  
    > ä¸¦æª¢æŸ¥åœ¨è€ƒæ…®å¯©è¨ˆé¢¨éšªå¾Œï¼Œæ˜¯å¦ä»ä½æ–¼å¯å®¹å¿éŒ¯èª¤ï¼ˆTMï¼‰ã€‚

    **ä½ ç¾åœ¨çœ‹åˆ°çš„çµæœé‡é»ï¼š**
    - âœ… `TÌ‚`ï¼šæ¯é«”èª¤å·®çš„é»ä¼°è¨ˆ
    - âœ… `CPI`ï¼šä¼°è¨ˆçš„ä¸ç¢ºå®šç¯„åœ
    - âœ… `U â‰¤ TM` â†’ **æ¥å—ï¼ˆAcceptï¼‰**
    - âœ… `U > TM` â†’ **æ‹’çµ•ï¼ˆRejectï¼‰**

    ğŸ‘‰ ä¸ç”¨èƒŒå…¬å¼ï¼Œå…ˆçœ‹çµè«–ã€‚
            """)

        # ---------- Tab 2: é€æ­¥å…¬å¼ ----------
        with tab2:
            with st.expander("Step 1ï¸âƒ£ æ¨£æœ¬é‡ä¼°è¨ˆï¼ˆSample sizeï¼‰", expanded=False):
                st.latex(r"""
    n = \left[ \frac{SD^\star \cdot (Z_A + Z_R) \cdot N}{TM - E^\star} \right]^2
    """)
                st.caption("é€™ä¸€æ­¥æ±ºå®šè¦æŠ½å¤šå°‘ç­†æ¨£æœ¬ã€‚")

            with st.expander("Step 2ï¸âƒ£ é»ä¼°è¨ˆï¼ˆPoint estimateï¼‰"):
                st.latex(r"""
    \bar{e} = \frac{\sum e_i}{n}, \quad \hat{T} = N \cdot \bar{e}
    """)

        with st.expander("Step 3ï¸âƒ£ ç²¾ç¢ºåº¦å€é–“ï¼ˆCPIï¼‰", expanded=False):

            st.markdown("**æ ¸å¿ƒè¨ˆç®—å¼ï¼ˆè€ƒè©¦ / åˆ¤æ–·ç”¨ï¼‰**")
            st.latex(r"""
        CPI = N \cdot Z_A \cdot \frac{SD}{\sqrt{n}} \sqrt{\frac{N-n}{N}}
        """
)
            # âœ… æ¬¡å±¤ expanderï¼šåªçµ¦æƒ³æ·±ç©¶çš„äºº
            with st.expander("ğŸ“ æ¨å°èˆ‡è£œå……èªªæ˜ï¼ˆé€²éšï¼‰"):
                st.latex(r"""
        SD = \sqrt{\frac{\sum (e_i - \bar{e})^2}{n-1}}
        """)
                st.latex(r"""
        SE(\bar{e}) = \frac{SD^\star}{\sqrt{n}} \sqrt{\frac{N-n}{N}}
        """)
                st.markdown("""
        - FPCï¼ˆfinite population correctionï¼‰åªåœ¨ **æŠ½æ¨£æ¯”ä¾‹ä¸å°** æ™‚é¡¯è‘—  
        - è€ƒè©¦é€šå¸¸ç›´æ¥çµ¦ CPIï¼Œä¸è¦æ±‚æ¨å°
                """)

            with st.expander("Step 4ï¸âƒ£ æ±ºç­–ï¼ˆDecision ruleï¼‰"):
                st.markdown("""
        - è‹¥ **ä¸Šé™ U â‰¤ TM** â†’ âœ… Accept  
        - è‹¥ **ä¸Šé™ U > TM** â†’ âŒ Reject  
                        """)

        # ---------- Tab 3: å®Œæ•´å®šç¾© ----------
    with tab3:
        st.markdown("### ğŸ“š å®Œæ•´å…¬å¼èˆ‡ç¬¦è™Ÿå®šç¾©ï¼ˆReferenceï¼‰")

        # ---------- å…¬å¼ ----------
        with st.expander("ğŸ“ å®Œæ•´å…¬å¼ï¼ˆæŸ¥é–±ç”¨ï¼‰", expanded=False):
            st.latex(r"n = \left[ \frac{SD^\star (Z_A + Z_R) N}{TM - E^\star} \right]^2")
            st.latex(r"\hat{T} = N \cdot \bar{e}")
            st.latex(r"CPI = N \cdot Z_A \cdot \frac{SD}{\sqrt{n}} \sqrt{\frac{N-n}{N}}")
            st.latex(r"L = \hat{T} - CPI,\quad U = \hat{T} + CPI")

        # ---------- Variable Glossary ----------
        with st.expander("ğŸ”¤ Variable Glossary / è®Šæ•¸å°ç…§è¡¨", expanded=False):
            st.table(pd.DataFrame({
                "Symbol": ["n","N","eÌ„","SDâ˜…","SD","ZA","ZR","TM","Eâ˜…","CPI","TÌ‚","L / U"],
                "Meaning (EN)": [
                    "Sample size",
                    "Population size",
                    "Sample mean error",
                    "Estimated population SD",
                    "Sample SD (STDEV.S)",
                    "ARIA Z-factor",
                    "ARIR Z-factor",
                    "Tolerable misstatement",
                    "Expected misstatement",
                    "Confidence precision interval (halfwidth)",
                    "Estimated total misstatement",
                    "Lower / Upper bound"
                ],
                "ä¸­æ–‡èªªæ˜": [
                    "æ¨£æœ¬æ•¸",
                    "æ¯é«”å¤§å°",
                    "æ¨£æœ¬å¹³å‡èª¤å·®",
                    "ä¼°è¨ˆæ¯é«”æ¨™æº–å·®",
                    "æ¨£æœ¬æ¨™æº–å·®",
                    "èª¤å—éšª Z å€¼",
                    "èª¤æ‹’éšª Z å€¼",
                    "å¯å®¹å¿éŒ¯èª¤",
                    "é æœŸéŒ¯èª¤",
                    "ç²¾ç¢ºåº¦å€é–“ï¼ˆåŠå¯¬ï¼‰",
                    "ç¸½èª¤å·®ä¼°è¨ˆ",
                    "å€é–“ä¸‹é™ï¼ä¸Šé™"
                ]
            }))


### Variable Glossary / è®Šæ•¸æ„ç¾©å°ç…§

| Symbol | Meaning (EN) | ä¸­æ–‡èªªæ˜ |
|:--:|:--|:--|
| *n* | Sample size | æ¨£æœ¬æ•¸ |
| *N* | Population size | æ¯é«”å¤§å° |
| *eÌ„* | Sample mean error | æ¨£æœ¬å¹³å‡èª¤å·® |
| *SDâ˜…* | Estimated population SD | ä¼°è¨ˆæ¯é«”æ¨™æº–å·® |
| *SD* | Sample SD (STDEV.S) | æ¨£æœ¬æ¨™æº–å·® |
| *ZA* | ARIA Z-factor | èª¤å—éšª Z å€¼ |
| *ZR* | ARIR Z-factor | èª¤æ‹’éšª Z å€¼ |
| *TM* | Tolerable misstatement | å¯å®¹å¿éŒ¯èª¤ |
| *Eâ˜…* | Expected misstatement | é æœŸéŒ¯èª¤ |
| *CPI* | Confidence precision interval | ç²¾ç¢ºåº¦å€é–“ï¼ˆåŠå¯¬ï¼‰ |
| *TÌ‚* | Estimated total misstatement | ç¸½èª¤å·®ä¼°è¨ˆ |
| *L*, *U* | Lower / Upper bound | å€é–“ä¸‹é™ / ä¸Šé™ |
